{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hcp_fmri_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vss245/nma_code/blob/master/hcp_fmri_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vATxcnlSUEqv",
        "colab_type": "text"
      },
      "source": [
        "# Intro and theory\n",
        "Dataset: HCP fMRI dataset, preprocessed and parcellated into 360 ROIs\n",
        "\n",
        "Task: Observing shapes moving either randomly or appearing to interact \"socially\"\n",
        " \n",
        "Question: how does the brain encode viewing social interaction?\n",
        "\n",
        "ROIs: temporoparietal junction, superior temporal sulcus, medial prefrontal cortex, fusiform gyrus, occipital gyrus, amygdala, insula \n",
        "\n",
        "Model: \n",
        "- ROIs indicated above interact with each other throughout this process of observing social interaction\n",
        "- We can measure this interaction via effective connectivity (e.g. Granger causality)\n",
        "- Viewing social interaction will increase GC between the ROIs, whereas random motion will not (control: random network, such as lower visual areas) \n",
        "\n",
        "Approach:\n",
        "- extract time series for every subject for these ROIs in both conditions\n",
        "- calculate GC between them (multivariate GC? fit a VAR?)\n",
        "\n",
        "Hypothesis: viewing social interaction increases connectivity between areas within the \"social network\" of the brain\n",
        "\n",
        "Statistics: \n",
        "- due to the structure of the experiment, we obtain GC separately for each condition per run and average across runs\n",
        "- after that, we have 1 GC value per condition per pairs of regions per subject (potentially we can subtract the two GC values and just look at the GC condition difference per pairs of regions per subject)\n",
        "- group level stats: ANOVA \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3skn13iG1Em",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-F2lyLgG-4u",
        "colab_type": "text"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDZlL8KNG3zO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The download cells will store the data in nested directories starting here:\n",
        "HCP_DIR = \"./hcp\"\n",
        "if not os.path.isdir(HCP_DIR):\n",
        "  os.mkdir(HCP_DIR)\n",
        "\n",
        "# The data shared for NMA projects is a subset of the full HCP dataset\n",
        "N_SUBJECTS = 339\n",
        "\n",
        "# The data have already been aggregated into ROIs from the Glasesr parcellation\n",
        "N_PARCELS = 360\n",
        "\n",
        "# The acquisition parameters for all tasks were identical\n",
        "TR = 0.72  # Time resolution, in sec\n",
        "\n",
        "# The parcels are matched across hemispheres with the same order\n",
        "HEMIS = [\"Right\", \"Left\"]\n",
        "\n",
        "# Each experiment was repeated multiple times in each subject\n",
        "N_RUNS_REST = 4\n",
        "N_RUNS_TASK = 2\n",
        "\n",
        "# Time series data are organized by experiment, with each experiment\n",
        "# having an LR and RL (phase-encode direction) acquistion\n",
        "BOLD_NAMES = [\n",
        "  \"rfMRI_REST1_LR\", \"rfMRI_REST1_RL\",\n",
        "  \"rfMRI_REST2_LR\", \"rfMRI_REST2_RL\",\n",
        "  \"tfMRI_MOTOR_RL\", \"tfMRI_MOTOR_LR\",\n",
        "  \"tfMRI_WM_RL\", \"tfMRI_WM_LR\",\n",
        "  \"tfMRI_EMOTION_RL\", \"tfMRI_EMOTION_LR\",\n",
        "  \"tfMRI_GAMBLING_RL\", \"tfMRI_GAMBLING_LR\",\n",
        "  \"tfMRI_LANGUAGE_RL\", \"tfMRI_LANGUAGE_LR\",\n",
        "  \"tfMRI_RELATIONAL_RL\", \"tfMRI_RELATIONAL_LR\",\n",
        "  \"tfMRI_SOCIAL_RL\", \"tfMRI_SOCIAL_LR\"\n",
        "]\n",
        "\n",
        "# You may want to limit the subjects used during code development.\n",
        "# This will use all subjects:\n",
        "subjects = range(N_SUBJECTS)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jikvS2czHFRo",
        "colab_type": "text"
      },
      "source": [
        "# Loading functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkNre_7iG6wF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fname = \"hcp_task.tgz\"\n",
        "if not os.path.exists(fname):\n",
        "  !wget -qO $fname https://osf.io/s4h8j/download/\n",
        "  !tar -xzf $fname -C $HCP_DIR --strip-components=1"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWS3b16CI3l8",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Helper functions: get image index, load_timeseries, load_evs (provided)\n",
        "def get_image_ids(name):\n",
        "  \"\"\"Get the 1-based image indices for runs in a given experiment.\n",
        "\n",
        "    Args:\n",
        "      name (str) : Name of experiment (\"rest\" or name of task) to load\n",
        "    Returns:\n",
        "      run_ids (list of int) : Numeric ID for experiment image files\n",
        "\n",
        "  \"\"\"\n",
        "  run_ids = [\n",
        "    i for i, code in enumerate(BOLD_NAMES, 1) if name.upper() in code\n",
        "  ]\n",
        "  if not run_ids:\n",
        "    raise ValueError(f\"Found no data for '{name}''\")\n",
        "  return run_ids\n",
        "\n",
        "def load_timeseries(subject, name, runs=None, concat=True, remove_mean=True):\n",
        "  \"\"\"Load timeseries data for a single subject.\n",
        "  \n",
        "  Args:\n",
        "    subject (int): 0-based subject ID to load\n",
        "    name (str) : Name of experiment (\"rest\" or name of task) to load\n",
        "    run (None or int or list of ints): 0-based run(s) of the task to load,\n",
        "      or None to load all runs.\n",
        "    concat (bool) : If True, concatenate multiple runs in time\n",
        "    remove_mean (bool) : If True, subtract the parcel-wise mean\n",
        "\n",
        "  Returns\n",
        "    ts (n_parcel x n_tp array): Array of BOLD data values\n",
        "\n",
        "  \"\"\"\n",
        "  # Get the list relative 0-based index of runs to use\n",
        "  if runs is None:\n",
        "    runs = range(N_RUNS_REST) if name == \"rest\" else range(N_RUNS_TASK)\n",
        "  elif isinstance(runs, int):\n",
        "    runs = [runs]\n",
        "\n",
        "  # Get the first (1-based) run id for this experiment \n",
        "  offset = get_image_ids(name)[0]\n",
        "\n",
        "  # Load each run's data\n",
        "  bold_data = [\n",
        "      load_single_timeseries(subject, offset + run, remove_mean) for run in runs\n",
        "  ]\n",
        "\n",
        "  # Optionally concatenate in time\n",
        "  if concat:\n",
        "    bold_data = np.concatenate(bold_data, axis=-1)\n",
        "\n",
        "  return bold_data\n",
        "\n",
        "\n",
        "def load_single_timeseries(subject, bold_run, remove_mean=True):\n",
        "  \"\"\"Load timeseries data for a single subject and single run.\n",
        "  \n",
        "  Args:\n",
        "    subject (int): 0-based subject ID to load\n",
        "    bold_run (int): 1-based run index, across all tasks\n",
        "    remove_mean (bool): If True, subtract the parcel-wise mean\n",
        "\n",
        "  Returns\n",
        "    ts (n_parcel x n_timepoint array): Array of BOLD data values\n",
        "\n",
        "  \"\"\"\n",
        "  bold_path = f\"{HCP_DIR}/subjects/{subject}/timeseries\"\n",
        "  bold_file = f\"bold{bold_run}_Atlas_MSMAll_Glasser360Cortical.npy\"\n",
        "  ts = np.load(f\"{bold_path}/{bold_file}\")\n",
        "  if remove_mean:\n",
        "    ts -= ts.mean(axis=1, keepdims=True)\n",
        "  return ts\n",
        "\n",
        "def load_evs(subject, name, condition):\n",
        "  \"\"\"Load EV (explanatory variable) data for one task condition.\n",
        "\n",
        "  Args:\n",
        "    subject (int): 0-based subject ID to load\n",
        "    name (str) : Name of task\n",
        "    condition (str) : Name of condition\n",
        "\n",
        "  Returns\n",
        "    evs (list of dicts): A dictionary with the onset, duration, and amplitude\n",
        "      of the condition for each run.\n",
        "\n",
        "  \"\"\"\n",
        "  evs = []\n",
        "  for id in get_image_ids(name):\n",
        "    task_key = BOLD_NAMES[id - 1]\n",
        "    ev_file = f\"{HCP_DIR}/subjects/{subject}/EVs/{task_key}/{condition}.txt\"\n",
        "    ev = dict(zip([\"onset\", \"duration\", \"amplitude\"], np.genfromtxt(ev_file).T))\n",
        "    evs.append(ev)\n",
        "  return evs\n",
        "\n",
        "def condition_frames(run_evs, skip=0):\n",
        "  \"\"\"Identify timepoints corresponding to a given condition in each run.\n",
        "\n",
        "  Args:\n",
        "    run_evs (list of dicts) : Onset and duration of the event, per run\n",
        "    skip (int) : Ignore this many frames at the start of each trial, to account\n",
        "      for hemodynamic lag\n",
        "\n",
        "  Returns:\n",
        "    frames_list (list of 1D arrays): Flat arrays of frame indices, per run\n",
        "\n",
        "  \"\"\"\n",
        "  frames_list = []\n",
        "  for ev in run_evs:\n",
        "\n",
        "    # Determine when trial starts, rounded down\n",
        "    start = np.floor(ev[\"onset\"] / TR).astype(int)\n",
        "\n",
        "    # Use trial duration to determine how many frames to include for trial\n",
        "    duration = np.ceil(ev[\"duration\"] / TR).astype(int)\n",
        "\n",
        "    # Take the range of frames that correspond to this specific trial\n",
        "    frames = [s + np.arange(skip, d) for s, d in zip(start, duration)]\n",
        "\n",
        "    frames_list.append(np.concatenate(frames))\n",
        "\n",
        "  return frames_list\n",
        "\n",
        "\n",
        "def selective_average(timeseries_data, ev, skip=0):\n",
        "  \"\"\"Take the temporal mean across frames for a given condition.\n",
        "\n",
        "  Args:\n",
        "    timeseries_data (array or list of arrays): n_parcel x n_tp arrays\n",
        "    ev (dict or list of dicts): Condition timing information\n",
        "    skip (int) : Ignore this many frames at the start of each trial, to account\n",
        "      for hemodynamic lag\n",
        "\n",
        "  Returns:\n",
        "    avg_data (1D array): Data averaged across selected image frames based\n",
        "    on condition timing\n",
        "\n",
        "  \"\"\"\n",
        "  # Ensure that we have lists of the same length\n",
        "  if not isinstance(timeseries_data, list):\n",
        "    timeseries_data = [timeseries_data]\n",
        "  if not isinstance(ev, list):\n",
        "    ev = [ev]\n",
        "  if len(timeseries_data) != len(ev):\n",
        "    raise ValueError(\"Length of `timeseries_data` and `ev` must match.\")\n",
        "\n",
        "  # Identify the indices of relevant frames\n",
        "  frames = condition_frames(ev)\n",
        "\n",
        "  # Select the frames from each image\n",
        "  selected_data = []\n",
        "  for run_data, run_frames in zip(timeseries_data, frames):\n",
        "    selected_data.append(run_data[:, run_frames])\n",
        "\n",
        "  # Take the average in each parcel\n",
        "  avg_data = np.concatenate(selected_data, axis=-1).mean(axis=-1)\n",
        "\n",
        "  return avg_data"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPSifU15Ut8u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRgj7FnDHKbQ",
        "colab_type": "text"
      },
      "source": [
        "## Region info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXfFWz7qHJnk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "330336a9-96b6-4b72-c10e-0729af125e28"
      },
      "source": [
        "regions = np.load(f\"{HCP_DIR}/regions.npy\").T\n",
        "region_info = dict(\n",
        "    name=regions[0].tolist(),\n",
        "    network=regions[1],\n",
        "    myelin=regions[2].astype(np.float),\n",
        ")\n",
        "\n",
        "regionsdf = pd.DataFrame.from_dict(region_info)\n",
        "# make a dictionary with all of the above, figure out details later - mPFC?\n",
        "roi_names = ['STS', 'TPOJ', 'ACC_mPFC', 'fusiform', 'insula']\n",
        "roi_codes = [['STSdp', 'STSda', 'STSvp', 'STSva'],\n",
        "            ['TPOJ1',  'TPOJ2',  'TPOJ3'],\n",
        "            ['33pr',  'p24pr',  'a24pr',  'p24',  'a24',  'p32pr',   'a32pr',  'd32',  'p32',  's32',  '8BM',  '9m', '10v',  '10r', '25'],\n",
        "            ['FFC'],  \n",
        "            ['Ig']]\n",
        "\n",
        "# loop over all subregions within a region, get the indices, combine\n",
        "\n",
        "def load_subject_rois(subject,run):\n",
        "  '''\n",
        "  Takes:\n",
        "    subject index\n",
        "    run index\n",
        "  Returns:\n",
        "    region x timeseries\n",
        "  Load all ROI timeseries for each subject and run \n",
        "  Average between all the subregions => 1 ROI time series\n",
        "  '''\n",
        "\n",
        "  ts = np.squeeze(load_timeseries(subject,'SOCIAL',runs=run,concat=False))\n",
        "  ts_all_rois = []\n",
        "  roi_indexes = []\n",
        "  for r in range(len(roi_names)):\n",
        "    subreg_indexes = []\n",
        "    for sr in roi_codes[r]:\n",
        "      index_list = regionsdf.index[regionsdf['name'].str.contains(sr)].tolist()\n",
        "      subreg_indexes = subreg_indexes + index_list\n",
        "    roi_indexes.append(subreg_indexes)\n",
        "\n",
        "  for r in range(len(roi_names)):\n",
        "    ts_roi = np.mean(ts[roi_indexes[r],],0)\n",
        "    ts_all_rois.append(ts_roi)\n",
        "  return ts_all_rois\n",
        "\n",
        "\n",
        "s = load_subject_rois(1,0)\n",
        "np.shape(s)"
      ],
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 274)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 292
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YksE9meH1cK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "e9d91bf6-75eb-4b8f-e709-b703d07f9ddf"
      },
      "source": [
        "# Pick a random region to compare - V1\n",
        "region1 = subject_rois[0]#\n",
        "region2 = subject_rois[1][0]\n",
        "plt.plot(region1,label='Visual1') \n",
        "plt.plot(region2,label='Lang') \n",
        "plt.legend()\n",
        "# Why do they overlap so much?\n",
        "np.shape(subject_rois[0])"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(274,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIcPjO70t-xT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting data - selective_average function?\n",
        "https://neurostars.org/t/updates-to-hcp-data-loader-including-visualization/15525\n",
        "https://neurostars.org/t/some-helper-functions-for-loading-hcp/15241\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0sqXIoHH4GP",
        "colab_type": "text"
      },
      "source": [
        "# Granger causality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdbsnZ64YDNl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "65dcd088-3b27-4cab-ebee-9a34af6ec973"
      },
      "source": [
        "from statsmodels.tsa.stattools import grangercausalitytests\n",
        "# Checks if the TS in column 2 Granger-causes the TS in column 1\n",
        "def GC_two_regions(all_ts, region_name1,region_name2):\n",
        "  idx1 = regionsdf.index[regionsdf['name'].str.contains(region_name1)].tolist() # get indices\n",
        "  region1 = np.mean(all_ts[idx1,],axis = 0)\n",
        "  idx2 = regionsdf.index[regionsdf['name'].str.contains(region_name2)].tolist() # get indices\n",
        "  region2 = np.mean(all_ts[idx2,],axis = 0)\n",
        "  regions_combined = np.vstack((region1,region2)).T \n",
        "  grangercausalitytests(regions_combined,1,verbose=True)\n",
        "GC_two_regions(all_ts, 'STS','TPOJ') # For the entire experiment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Granger Causality\n",
            "number of lags (no zero) 1\n",
            "ssr based F test:         F=3.5137  , p=0.0614  , df_denom=544, df_num=1\n",
            "ssr based chi2 test:   chi2=3.5331  , p=0.0602  , df=1\n",
            "likelihood ratio test: chi2=3.5217  , p=0.0606  , df=1\n",
            "parameter F test:         F=3.5137  , p=0.0614  , df_denom=544, df_num=1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-hGNz2OXEUF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "cf48602f-0f65-4beb-a87d-69146a56e6be"
      },
      "source": [
        "# Extract condition runs\n",
        "subj_id = 0\n",
        "task = 'SOCIAL'\n",
        "all_ts_run0 = load_timeseries(subj_id, 'SOCIAL', runs=0) # Run 0\n",
        "# Mentalizing\n",
        "mental_frames = condition_frames(load_evs(subj_id, task, 'mental'))\n",
        "mental_ts = all_ts_run0[:,mental_frames[0]]\n",
        "# Random\n",
        "random_frames = condition_frames(load_evs(subj_id, task, 'rnd'))\n",
        "random_ts = all_ts_run0[:,random_frames[0]]\n",
        "# Run GC\n",
        "GC_two_regions(mental_ts, 'STS','TPOJ')\n",
        "GC_two_regions(random_ts, 'STS','TPOJ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Granger Causality\n",
            "number of lags (no zero) 1\n",
            "ssr based F test:         F=0.6842  , p=0.4114  , df_denom=60, df_num=1\n",
            "ssr based chi2 test:   chi2=0.7184  , p=0.3967  , df=1\n",
            "likelihood ratio test: chi2=0.7144  , p=0.3980  , df=1\n",
            "parameter F test:         F=0.6842  , p=0.4114  , df_denom=60, df_num=1\n",
            "\n",
            "Granger Causality\n",
            "number of lags (no zero) 1\n",
            "ssr based F test:         F=0.0060  , p=0.9384  , df_denom=92, df_num=1\n",
            "ssr based chi2 test:   chi2=0.0062  , p=0.9372  , df=1\n",
            "likelihood ratio test: chi2=0.0062  , p=0.9372  , df=1\n",
            "parameter F test:         F=0.0060  , p=0.9384  , df_denom=92, df_num=1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEqSp71PgBDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MGltFR6LLwP",
        "colab_type": "text"
      },
      "source": [
        "## GC in nipype\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SaM-dFrLO7o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "d00c50eb-0aa7-4579-b7f2-6e66300f5fa7"
      },
      "source": [
        "!pip install nitime\n",
        "import nitime\n",
        "import nitime.analysis as nta\n",
        "import nitime.timeseries as ts\n",
        "import nitime.utils as tsu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nitime in /usr/local/lib/python3.6/dist-packages (0.8.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from nitime) (0.29.21)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from nitime) (1.18.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from nitime) (2.4)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.6/dist-packages (from nitime) (3.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from nitime) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from nitime) (3.2.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->nitime) (4.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nitime) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nitime) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nitime) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nitime) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->nitime) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4PMTu63LVq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TR = 0.72 # time res\n",
        "f_ub = 0.15\n",
        "f_lb = 0.02 # physiologically relevant freqs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xErWwNraLufd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8b53f0ef-a13c-4b0e-a247-a422909c36ec"
      },
      "source": [
        "# stack regions\n",
        "idx1 = regionsdf.index[regionsdf['name'].str.contains('STS')].tolist() # get indices\n",
        "region1 = np.mean(all_ts[idx1,],axis = 0)\n",
        "idx2 = regionsdf.index[regionsdf['name'].str.contains('TPOJ')].tolist() # get indices\n",
        "region2 = np.mean(all_ts[idx2,],axis = 0)\n",
        "#idx3 = regionsdf.index[regionsdf['name'].str.contains('V1')].tolist() # get indices\n",
        "#region3 = np.mean(all_ts[idx2,],axis = 0)\n",
        "regions_combined = np.vstack((region1,region2)) #region3))\n",
        "np.shape(regions_combined)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 274)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JmK_QwsL_90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pdata = tsu.percent_change(regions_combined) #convert to percentage change ??\n",
        "time_series = ts.TimeSeries(pdata, sampling_interval=TR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Exta5bBeMEn2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "433feec3-7065-46b5-afd9-f71b2a65627b"
      },
      "source": [
        "G = nta.GrangerAnalyzer(time_series, order=1)\n",
        "freq_idx_G = np.where((G.frequencies > f_lb) * (G.frequencies < f_ub))[0] # find where relevant frequencies are\n",
        "g_caus = np.mean(G.causality_xy[:, :, freq_idx_G] - G.causality_yx[:, :, freq_idx_G],-1) # diff between two directions\n",
        "plt.imshow(g_caus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f09f5774208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq1G7DiFNzR3",
        "colab_type": "text"
      },
      "source": [
        "# ANOVA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SVC55cdN0tf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}